{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "asSOY-UffIID"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUtdVYL8YfE1"
      },
      "source": [
        "#downloading model from my github\n",
        "#github id --> https://github.com/abhishekjha2468\n",
        "import requests\n",
        "url = 'https://github.com/abhishekjha2468/Dont-Overfit/blob/main/LG.pkl?raw=true'\n",
        "with open(\"LG.pkl\",'wb') as output_file: output_file.write(requests.get(url).content)\n",
        "url = 'https://github.com/abhishekjha2468/Dont-Overfit/blob/main/XGBoost.pkl?raw=true'\n",
        "with open(\"XGBoost.pkl\",'wb') as output_file: output_file.write(requests.get(url).content)\n",
        "url = 'https://github.com/abhishekjha2468/Dont-Overfit/blob/main/LGBM.pkl?raw=true'\n",
        "with open(\"LGMB.pkl\",'wb') as output_file: output_file.write(requests.get(url).content)\n",
        "url = 'https://github.com/abhishekjha2468/Dont-Overfit/blob/main/LASSO.pkl?raw=true'\n",
        "with open(\"LASSO.pkl\",'wb') as output_file: output_file.write(requests.get(url).content)\n",
        "url = 'https://github.com/abhishekjha2468/Dont-Overfit/blob/main/scaler.pkl?raw=true'\n",
        "with open(\"scaler.pkl\",'wb') as output_file: output_file.write(requests.get(url).content)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-diLajlQbspI"
      },
      "source": [
        "#loading model from downloaded pickle file\n",
        "import pickle\n",
        "with open(\"/content/LG.pkl\", 'rb') as file:  LR_Model = pickle.load(file)\n",
        "with open(\"/content/XGBoost.pkl\", 'rb') as file:  XGB_Model = pickle.load(file)\n",
        "with open(\"/content/LGMB.pkl\", 'rb') as file:  LGMB_Model = pickle.load(file)\n",
        "with open(\"/content/LASSO.pkl\", 'rb') as file:  LASSO_Model = pickle.load(file)\n",
        "with open(\"/content/scaler.pkl\", 'rb') as file:  scaler = pickle.load(file)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eObFRga_aR0h"
      },
      "source": [
        "\n",
        "def predict(query):\n",
        "  \"\"\"\n",
        "  This function take query dataset as an input and return its predicted class probability \n",
        "  Note: input dataframe with 300 columns, named 0-299\n",
        "  \"\"\"\n",
        "  df=pd.DataFrame(scaler.transform(query[list(map(str,range(300)))]))\n",
        "  df[\"ceil_min\"]=list(map(lambda x: math.ceil(min(x)) ,scaler.transform(query[list(map(str,range(300)))])))\n",
        "  df[\"mean\"]=list(map(lambda x: np.mean(x) ,scaler.transform(query[list(map(str,range(300)))])))\n",
        "  df[\"sum\"]=list(map(lambda x: np.sum(x) ,scaler.transform(query[list(map(str,range(300)))])))\n",
        "  df[\"max_x_mean\"]=list(map(lambda x: np.max(x)*np.mean(x) ,scaler.transform(query[list(map(str,range(300)))])))\n",
        "  df[\"min_x_sum\"]=list(map(lambda x: np.min(x)*np.sum(x) ,scaler.transform(query[list(map(str,range(300)))])))\n",
        "  lr_pred=LR_Model.predict_proba(df)[:,1]\n",
        "  xgb_pred=XGB_Model.predict_proba(df)[:,1]\n",
        "  lgmb_pred=LGMB_Model.predict_proba(df)[:,1]\n",
        "  lasso_pred=LASSO_Model.predict(df)\n",
        "  pred=lr_pred*0.1 + xgb_pred*0.1 + lgmb_pred*0.1 + lasso_pred*0.7\n",
        "  return pred"
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}